{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfce35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2544/2544 [10:50<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to G:\\Public\\CYGNSS_clip_csv\\All_cygnss_data_2023.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Directory containing the CSV files\n",
    "input_dir = r\"G:\\Public\\CYGNSS_clip_csv\"\n",
    "output_file = r\"G:\\Public\\CYGNSS_clip_csv\\All_cygnss_data_2023.csv\"\n",
    "\n",
    "# Function to extract satellite ID and date from the filename\n",
    "def extract_info_from_filename(filename):\n",
    "    match = re.search(r\"cyg(\\d+)\\.ddmi\\.s(\\d{8})-\", filename)\n",
    "    if match:\n",
    "        satellite = f\"cyg{match.group(1)}\"\n",
    "        date = match.group(2)\n",
    "        return satellite, date\n",
    "    return None, None\n",
    "\n",
    "# Function to calculate the coordinates of the corners of a square\n",
    "def calculate_square(lat, lon, km_radius):\n",
    "    earth_radius = 6371\n",
    "    delta_lat = (km_radius / earth_radius) * (180 / np.pi)\n",
    "    delta_lon = (km_radius / (earth_radius * np.cos(np.radians(lat)))) * (180 / np.pi)\n",
    "\n",
    "    return {\n",
    "        \"top_left_lat\": lat + delta_lat,\n",
    "        \"top_left_lon\": lon - delta_lon,\n",
    "        \"top_right_lat\": lat + delta_lat,\n",
    "        \"top_right_lon\": lon + delta_lon,\n",
    "        \"bottom_left_lat\": lat - delta_lat,\n",
    "        \"bottom_left_lon\": lon - delta_lon,\n",
    "        \"bottom_right_lat\": lat - delta_lat,\n",
    "        \"bottom_right_lon\": lon + delta_lon\n",
    "    }\n",
    "\n",
    "# List to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for file in tqdm(os.listdir(input_dir)):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_dir, file)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Drop rows with any missing values\n",
    "            df = df.dropna()\n",
    "\n",
    "            # Extract satellite and date information\n",
    "            satellite, date = extract_info_from_filename(file)\n",
    "\n",
    "            if satellite and date:\n",
    "                # Add satellite and date information to the dataframe\n",
    "                df[\"satellite\"] = satellite\n",
    "                df[\"date\"] = date\n",
    "\n",
    "                # Recalculate the corner coordinates with km_radius = 1.5\n",
    "                new_coords = df.apply(lambda row: calculate_square(row[\"sp_lat\"], row[\"sp_lon\"], 1.5), axis=1)\n",
    "                new_coords_df = pd.DataFrame(new_coords.tolist())\n",
    "                \n",
    "                # Merge the new coordinates with the dataframe\n",
    "                df = pd.concat([df, new_coords_df], axis=1)\n",
    "\n",
    "                # Append the dataframe to the list\n",
    "                dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file}: {e}\")\n",
    "\n",
    "# Concatenate all dataframes\n",
    "if dataframes:\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Save the merged dataframe to a CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"Merged data saved to {output_file}\")\n",
    "else:\n",
    "    print(\"No valid data to merge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab0d7c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_111132\\1374485608.py:12: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 02 saved to G:\\Public\\CYGNSS_clip_csv\\Merged_data\\cygnss_data_month_02.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the merged CSV file\n",
    "input_csv = r\"G:\\Public\\CYGNSS_clip_csv\\Merged_data\\All_cygnss_data_2023.csv\"\n",
    "output_dir = r\"G:\\Public\\CYGNSS_clip_csv\\Merged_data\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read the merged CSV file\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Check if the 'date' column exists and format is correct\n",
    "if 'date' in df.columns:\n",
    "    try:\n",
    "        # Convert 'date' column to datetime format\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')\n",
    "\n",
    "        # Extract month from the date\n",
    "        df['month'] = df['date'].dt.month\n",
    "\n",
    "        # Remove duplicate columns (if any)\n",
    "        df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "        # Split data into 12 files by month\n",
    "        for month in range(2, 3):\n",
    "            month_df = df[df['month'] == month]\n",
    "\n",
    "            if not month_df.empty:\n",
    "                # Create the output file name\n",
    "                output_file = os.path.join(output_dir, f\"cygnss_data_month_{month:02}.csv\")\n",
    "\n",
    "                # Save the data for the current month\n",
    "                month_df.to_csv(output_file, index=False)\n",
    "                print(f\"Data for month {month:02} saved to {output_file}\")\n",
    "            else:\n",
    "                print(f\"No data found for month {month:02}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the 'date' column: {e}\")\n",
    "else:\n",
    "    print(\"The 'date' column is missing from the input CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e189ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: cygnss_data_month_01.csv\n",
      "Successfully processed and saved: cygnss_data_month_01.csv\n",
      "Processing file: cygnss_data_month_02.csv\n",
      "Successfully processed and saved: cygnss_data_month_02.csv\n",
      "Processing file: cygnss_data_month_03.csv\n",
      "Successfully processed and saved: cygnss_data_month_03.csv\n",
      "Processing file: cygnss_data_month_04.csv\n",
      "Successfully processed and saved: cygnss_data_month_04.csv\n",
      "Processing file: cygnss_data_month_05.csv\n",
      "Successfully processed and saved: cygnss_data_month_05.csv\n",
      "Processing file: cygnss_data_month_06.csv\n",
      "Successfully processed and saved: cygnss_data_month_06.csv\n",
      "Processing file: cygnss_data_month_07.csv\n",
      "Successfully processed and saved: cygnss_data_month_07.csv\n",
      "Processing file: cygnss_data_month_08.csv\n",
      "Successfully processed and saved: cygnss_data_month_08.csv\n",
      "Processing file: cygnss_data_month_09.csv\n",
      "Successfully processed and saved: cygnss_data_month_09.csv\n",
      "Processing file: cygnss_data_month_10.csv\n",
      "Successfully processed and saved: cygnss_data_month_10.csv\n",
      "Processing file: cygnss_data_month_11.csv\n",
      "Successfully processed and saved: cygnss_data_month_11.csv\n",
      "Processing file: cygnss_data_month_12.csv\n",
      "Successfully processed and saved: cygnss_data_month_12.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the folder path and file pattern\n",
    "folder_path = r\"G:\\Public\\CYGNSS_clip_csv\\Merged_data\"\n",
    "file_pattern = \"cygnss_data_month_\"\n",
    "columns_to_drop = 9  # Number of columns to delete\n",
    "\n",
    "# Process each file from month 01 to 12\n",
    "for month in range(1, 13):\n",
    "    file_name = f\"{file_pattern}{month:02}.csv\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_name}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "    \n",
    "    # Load the file into a DataFrame\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if df.shape[1] <= columns_to_drop:\n",
    "            print(f\"File {file_name} has fewer than {columns_to_drop} columns. Skipping deletion.\")\n",
    "            continue\n",
    "        \n",
    "        # Drop the last 9 columns\n",
    "        df = df.iloc[:, :-columns_to_drop]\n",
    "        \n",
    "        # Save the modified DataFrame back to the same file\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Successfully processed and saved: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c76b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files merged successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(directory, output_file):\n",
    "    # Get a list of all CSV files in the directory\n",
    "    csv_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "    # List to hold individual DataFrames\n",
    "    data_frames = []\n",
    "\n",
    "    # Read each CSV and append to the list\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        data_frames.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    merged_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = r'G:\\Public\\CYGNSS_clip_csv\\Merged_data\\Random_forest_training_without_location'\n",
    "\n",
    "# Output file path\n",
    "output_file = r'G:\\Public\\CYGNSS_clip_csv\\Merged_data\\Random_forest_training_without_location\\merged_water_fraction.csv'\n",
    "\n",
    "# Merge the CSV files\n",
    "merge_csv_files(directory, output_file)\n",
    "\n",
    "print(\"CSV files merged successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f9f913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV split into two files:\n",
      "- G:\\Public\\CYGNSS_clip_csv\\Merged_data\\cygnss_data_month_11_a.csv\n",
      "- G:\\Public\\CYGNSS_clip_csv\\Merged_data\\cygnss_data_month_11_b.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the large CSV\n",
    "file_path = r\"G:\\Public\\CYGNSS_clip_csv\\Merged_data\\cygnss_data_month_11.csv\"  # Replace with your file path\n",
    "output_file1 = r\"G:\\Public\\CYGNSS_clip_csv\\Merged_data\\cygnss_data_month_11_a.csv\"\n",
    "output_file2 = r\"G:\\Public\\CYGNSS_clip_csv\\Merged_data\\cygnss_data_month_11_b.csv\"\n",
    "\n",
    "# Read the CSV\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Find the midpoint\n",
    "midpoint = len(data) // 2\n",
    "\n",
    "# Split the data\n",
    "data_part1 = data.iloc[:midpoint]\n",
    "data_part2 = data.iloc[midpoint:]\n",
    "\n",
    "# Save the two parts\n",
    "data_part1.to_csv(output_file1, index=False)\n",
    "data_part2.to_csv(output_file2, index=False)\n",
    "\n",
    "print(f\"CSV split into two files:\\n- {output_file1}\\n- {output_file2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6917c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "Skipping line 467248: NULL byte detected. This byte cannot be processed in Python's native csv library at the moment, so please pass in engine='c' instead\n",
      "Skipping line 1110913: NULL byte detected. This byte cannot be processed in Python's native csv library at the moment, so please pass in engine='c' instead\n",
      "Skipping line 1256215: NULL byte detected. This byte cannot be processed in Python's native csv library at the moment, so please pass in engine='c' instead\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
      "C:\\Users\\hyou34\\AppData\\Local\\Temp\\ipykernel_7812\\784722317.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files merged successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(directory, output_file):\n",
    "    # Get a list of all CSV files in the directory\n",
    "    csv_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "    # List to hold individual DataFrames\n",
    "    data_frames = []\n",
    "\n",
    "    # Read each CSV and append to the list\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True, engine='python')\n",
    "            data_frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    merged_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = r\"G:\\Public\\CYGNSS_clip_csv\\Merged_data\\Random_forest_training_with_location\"\n",
    "\n",
    "# Output file path\n",
    "output_file = r\"G:\\Public\\CYGNSS_clip_csv\\Merged_data\\Random_forest_training_with_location\\merged_water_fraction.csv\"\n",
    "\n",
    "# Merge the CSV files\n",
    "merge_csv_files(directory, output_file)\n",
    "\n",
    "print(\"CSV files merged successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18257fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
